---
title: "coastal_ts_variable_selection"
author: "Bryan Milstead"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(randomForest)
# library(caret)
```

## Introduction
We are developing a trophic state index for transitional (estuarine and coastal) waters.  Part of this process involves selection of predictor variables.  We use random forest to determine the most imporant variables.


## Data
* Data [CoastalWQ_20170928.csv] and code [betty_code_20171004.r], received from Betty on 20180207
* using Betty code, download and organize the data
    - rename some fields
    - filter for year == 2010, region != "Insular", region != "Great Lakes", col_loc == "SURFACE", and visnum == 1
    - restrict to complete cases

```{r read, include=FALSE, echo=FALSE, cache=FALSE} 
# get the data
coastalData<-read.csv(file="CoastalWQ_20170928.csv",header=TRUE)

# rename fields
coastalData<-rename(coastalData, chla=CHLA..ug.L.)
coastalData<-rename(coastalData, TN=TN..mgN.L.)
coastalData<-rename(coastalData, DIN=DIN..mgN.L.)
coastalData<-rename(coastalData, TP=TP..mgP.L.)
coastalData<-rename(coastalData, DIP=DIP..mgP.L.)
coastalData<-rename(coastalData, DIN_DIP=DIN.DIP..Molar.)
coastalData<-rename(coastalData, TN_TP=TN.TP..Molar.)
coastalData<-rename(coastalData, secchi=SECCHI_MEAN..m.)
coastalData<-rename(coastalData, TSS=TSS..mg.L.)

# change all names to lowercase

names(coastalData)<-tolower(names(coastalData))

# choose predictor variables

predVar<-c(7,8,9,10,11,14,15,16,17,18,20)

# 2010 only model
coast2010<-filter(coastalData, sampyear==2010, region != "Insular", 
                  region != "Great Lakes", col_loc == "SURFACE", visnum == 1)

# keep only complete cases for chla
x<-complete.cases(coast2010[,c(13, predVar)])
coast2010.cc<-coast2010[x,]
```

## Analysis

* run random forest
    - save as coast2010rf.rda
* create the variable importance plot & table

```{r rf, include=FALSE, echo=FALSE, eval=FALSE} 
set.seed(1956)
coast2010.rf<-randomForest(coast2010.cc[,predVar],log1p(coast2010.cc[,13]),ntree=10000,
                           importance=TRUE,proximity=TRUE,na.action=na.omit)

save(coast2010.rf, file='coast2010.rf.rda')

# variable importance plot

jpeg('coast2010_variable_importance.jpeg')
varImpPlot(coast2010.rf,type = 1)
dev.off()
```

```{r rf1, include=FALSE, echo=FALSE, eval=TRUE} 
#since eval = FALSE (above) need to reload the rf results
load(file='coast2010.rf.rda')
```

## Results

* response variable is "chla"
* randomForest provides two measures of variables importance ("%IncMSE" and "IncNodePurity")and the SD of importance (importanceSD); we are using "%IncMSE" but change the name to "per_inc_mse"
* a scaled variable importance is caluclated by dividing per_inc_mse / importanceSD (or use the function [importance])
    - below are information on the importance values from ?importance
    
>Here are the definitions of the variable importance measures. The first measure is computed from permuting OOB data: For each tree, the prediction error on the out-of-bag portion of the data is recorded (error rate for classification, MSE for regression). Then the same is done after permuting each predictor variable. The difference between the two are then averaged over all trees, and normalized by the standard deviation of the differences. If the standard deviation of the differences is equal to 0 for a variable, the division is not done (but the average is almost always equal to 0 in that case).

>The second measure is the total decrease in node impurities from splitting on the variable, averaged over all trees. For classification, the node impurity is measured by the Gini index. For regression, it is measured by residual sum of squares.

* predictor variables, and importance and scaled importance values are shown below ("coast2010_rf_imp.csv")

```{r kable, include=TRUE, echo=FALSE, cache=FALSE} 
# importance table
imp<-as.data.frame(importance(coast2010.rf)) #get the importance values (%IncMSE)
imp$variable <- row.names(imp) #variables are the row.names
names(imp)[1]<-"per_inc_mse"  # the % sign is no good

imp<-select(imp, variable, per_inc_mse, IncNodePurity) %>% arrange(desc(per_inc_mse)) %>%
  mutate(variable = ifelse(variable == 'subregions', 'subregion', variable)) %>%
  mutate(variable = ifelse(variable == 'din_dip', 'din dip ratio', variable))

imp$variable<-factor(imp$variable, levels = imp$variable)

write.csv(imp, 'coast2010_rf_imp.csv')

knitr::kable(imp)
```

* importance values shown graphically ("coast2010_variable_importance.jpeg")

```{r fig1, include=FALSE, echo=FALSE, cache=FALSE} 
#reverse order of variables for plotting
imp1<-arrange(imp, per_inc_mse)
imp1$variable<-factor(imp1$variable, levels = imp1$variable)


gg <- ggplot(data=imp1, aes(x=variable, y=per_inc_mse)) +
    geom_bar(stat="identity") + coord_flip() +
  labs(title = "Random Forest Variable Importance", 
       y = '% Increase in Mean Squared Error') +
  theme(axis.title.y=element_blank(), text = element_text(size=20), 
        plot.title = element_text(hjust = 0.5)) 

jpeg(filename = "coast2010_variable_importance.jpeg", quality = 100)
gg
dev.off()
```

```{r fig1a, include=TRUE, echo=FALSE, cache=FALSE} 
gg
```

## Variable Selection Paragraph

The first step in the modelling process is to decide which variables to include.  Of the hundreds of measurements taken during the National Coastal Assessment eleven were selected *apriori* as being potentially useful in predicting the trophic state of transitional waters.  These variables are shown in Table 1. Random forest modeling was used to select an optimal reduced subset of the original predictor variables.  Random forest modeling is a machine learning algorithm that builds numerous statistical decision trees in order to attain a consensus predictor model (Breiman 2001). Each tree is based on recursively bootstrapped data, and the out-of-bag (OOB) data, cases left out of the sample, provides an unbiased estimation of model error and measure of predictor variable importance. Random forest modeling was conducted in R (R Core Team 2016) with the randomForest package (Liaw and Wiener 2002). The random forest model with 10,000 trees was used to determine which of the original eleven variables had the most impact on predicting Chlorophyll *a* values, a proxy for trophic state. Based on the model, each variable was assigned an importance value based on the percent reduction in to the OOB mean squared error for the (averaged over all trees and normalized by dividing by the standard deviation).  The importance measures are shown in Table 1 and Figure 1.  From Figure 1 it is apparent that the data fallinto at least three groups.  Total nitrogen (tn) has the greatest impact followed by five variables of midlevel and five of lower level importances (Table 1 and Figure 1).  The six variables with high or mid-level importances were retained for model development and the five lowest importance variables were eliminated.

## References

Breiman, L. (2001). Random forests. Machine learning, 45(1):5–32.

Liaw, A. andWiener,M. (2002). Classification and regression by randomforest. r news 2 (3): 18–22. URL: http://CRAN. R-project. org/doc/Rnews.

R Core Team (2016). R: A Language and Environment for Statistical Computing. R Foundation for Statistical Computing, Vienna, Austria.


